{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d94567-509b-4d26-8e2b-cd2d7c2fd1c5",
   "metadata": {},
   "source": [
    "# Air Pollution Forecasting - Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5f9b8ed-fcd6-4c65-9c1d-d9baf0c9b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f6a3199-b275-4526-92b1-b46e1bcc34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_imputed_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b303a36c-9c32-456d-bc7a-ca4321c0cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0333c487-d45e-42f3-b876-8c9d6eef188b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_local</th>\n",
       "      <th>temp</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>so2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/2022 0:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>385</td>\n",
       "      <td>1339.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>491.7</td>\n",
       "      <td>347.67</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2022 1:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>404</td>\n",
       "      <td>1437.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>508.3</td>\n",
       "      <td>359.33</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/02/2022 2:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>421</td>\n",
       "      <td>1535.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>371.00</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/02/2022 3:00</td>\n",
       "      <td>12.2</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>425</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>529.3</td>\n",
       "      <td>374.00</td>\n",
       "      <td>275.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/02/2022 4:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>430</td>\n",
       "      <td>1782.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>533.7</td>\n",
       "      <td>377.00</td>\n",
       "      <td>253.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp_local  temp city_name country_code  aqi      co   no2    o3  \\\n",
       "0  01/02/2022 0:00  12.6    Gujrāt           PK  385  1339.8  76.0  10.7   \n",
       "1  01/02/2022 1:00  11.5    Gujrāt           PK  404  1437.6  76.0   9.3   \n",
       "2  01/02/2022 2:00  11.9    Gujrāt           PK  421  1535.5  76.0   8.0   \n",
       "3  01/02/2022 3:00  12.2    Gujrāt           PK  425  1659.0  68.3   5.3   \n",
       "4  01/02/2022 4:00  11.9    Gujrāt           PK  430  1782.5  60.7   2.7   \n",
       "\n",
       "    pm10    pm25    so2  \n",
       "0  491.7  347.67  238.0  \n",
       "1  508.3  359.33  268.0  \n",
       "2  525.0  371.00  298.0  \n",
       "3  529.3  374.00  275.7  \n",
       "4  533.7  377.00  253.3  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91f9c6e6-4fa1-40b3-bc7f-d27dd6bc9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['temp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7adb5951-6756-4afa-8b89-6470edced23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "            \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2935419f-87a8-436a-ab4e-02569ae279a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "346508c6-2026-42f9-a64e-2bc56e8df320",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data.values\n",
    "\n",
    "values = values.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4bbc768a-cd39-45ea-8833-38f57f7f32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19371, 336)\n"
     ]
    }
   ],
   "source": [
    "# converting the dataset as supervised learning\n",
    "reframed = series_to_supervised(scaled, 168, 168)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a5260e5-4686-47d6-8e06-3c19881658cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13140, 1, 335) (13140,) (6231, 1, 335) (6231,)\n"
     ]
    }
   ],
   "source": [
    "values = reframed.values\n",
    "\n",
    "# We train the model on the 1st 3 years and then test on the last year (for now)\n",
    "n_train_hours = int(365 * 24 * 1.5)\n",
    "\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D :- (no.of samples, no.of timesteps, no.of features)\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6aebc9de-e069-4d0d-b2f3-3608608da992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Conv2D, ConvLSTM1D, RepeatVector, TimeDistributed, Conv1D, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a128f6fe-95e7-4aad-8e86-132430d1569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">76,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,512</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m76,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)                 │           \u001b[38;5;34m1,512\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,024</span> (308.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,024\u001b[0m (308.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,024</span> (308.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,024\u001b[0m (308.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Input(shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model3.add(GRU(64))\n",
    "model3.add(Dense(8, 'relu'))\n",
    "model3.add(Dense(168, 'linear'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a616548-849e-410d-b572-028e7862ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# cp3 = ModelCheckpoint('model3/', save_best_only=True)\n",
    "model3.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a51e9fd-857a-4a33-8a58-706be1b1229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_9748\\2137486928.py\", line 1, in <module>\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 60, in train_step\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 322, in compute_loss\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 605, in __call__\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 641, in call\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 42, in __call__\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1154, in mean_squared_error\n\nIncompatible shapes: [32] vs. [32,168]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_337044]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/mean_squared_error/sub defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 604, in run_forever\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 359, in execute_request\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 446, in do_execute\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_9748\\2137486928.py\", line 1, in <module>\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 325, in fit\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 118, in one_step_on_iterator\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 106, in one_step_on_data\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 60, in train_step\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\", line 322, in compute_loss\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 605, in __call__\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\", line 641, in call\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\loss.py\", line 42, in __call__\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 22, in call\n\n  File \"C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses\\losses.py\", line 1154, in mean_squared_error\n\nIncompatible shapes: [32] vs. [32,168]\n\t [[{{node compile_loss/mean_squared_error/sub}}]] [Op:__inference_one_step_on_iterator_337044]"
     ]
    }
   ],
   "source": [
    "model3.fit(train_X, train_y, validation_split=0.2, verbose=2, shuffle=False, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6468a1d-d4df-4009-bf38-4474f77272f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13140"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_X.shape[1] \n",
    "train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5baf67d-d6ff-43c3-ac1b-9429e36a6b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">107,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │         \u001b[38;5;34m107,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m80,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,101</span> (734.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m188,101\u001b[0m (734.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,101</span> (734.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m188,101\u001b[0m (734.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Input(shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "# model.add(RepeatVector(1))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d74c3f4a-dcb4-4086-9bc5-4bfd0f422f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 - 3s - 85ms/step - loss: 0.0453 - val_loss: 0.0397\n",
      "Epoch 2/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0129 - val_loss: 0.0363\n",
      "Epoch 3/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0078 - val_loss: 0.0211\n",
      "Epoch 4/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0057 - val_loss: 0.0138\n",
      "Epoch 5/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 6/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 8/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "40/40 - 0s - 11ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 11/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 12/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "40/40 - 0s - 10ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 14/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 15/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 16/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 17/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 18/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 19/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 20/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 23/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "40/40 - 1s - 14ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 25/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 27/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 28/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 29/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 30/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "40/40 - 0s - 10ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 33/50\n",
      "40/40 - 1s - 16ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "40/40 - 0s - 12ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 38/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "40/40 - 0s - 9ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "40/40 - 1s - 17ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 42/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 43/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 44/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "40/40 - 0s - 8ms/step - loss: 0.0017 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=50, batch_size=264, validation_split=0.2, verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec94ec25-56d1-4466-a75b-325bee91f9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(history.history['loss'], label='train', linewidth = 2.5)\n",
    "plt.plot(history.history['val_loss'], label='test',  linewidth = 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "375ab757-4d10-4016-9093-fe370463c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "(6398, 1)\n",
      "(6398,)\n"
     ]
    }
   ],
   "source": [
    "testPredict = model.predict(test_X)\n",
    "print(testPredict.shape)\n",
    "testPredict = testPredict.ravel()\n",
    "\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbfc0c63-c7c6-402e-b9a9-cce131a96d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true = test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d28aca89-2e7f-4494-9ccf-8367e4712d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "poll = np.array(df[\"aqi\"])\n",
    "\n",
    "meanop = poll.mean()\n",
    "stdop = poll.std()\n",
    "\n",
    "y_test_true = y_test_true*stdop + meanop\n",
    "testPredict = testPredict*stdop + meanop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b98e5646-5dc1-4c56-8985-5ff1cb501d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE = 181.21182\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test_y, testPredict))\n",
    "print(\"Test RMSE =\"  ,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f742359-e1bb-462e-9388-70e7266079b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef54c3b-2a1c-46c0-bf8f-b05c06f58270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f65717-f4d0-4aff-a122-f9fa24523707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de14f63-961f-4ea0-a817-d9fad889fff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d42c8f8-eeda-4ef4-a69c-a11253246e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_local</th>\n",
       "      <th>temp</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>so2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/2022 0:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>385</td>\n",
       "      <td>1339.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>491.7</td>\n",
       "      <td>347.67</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2022 1:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>404</td>\n",
       "      <td>1437.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>508.3</td>\n",
       "      <td>359.33</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/02/2022 2:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>421</td>\n",
       "      <td>1535.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>371.00</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/02/2022 3:00</td>\n",
       "      <td>12.2</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>425</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>529.3</td>\n",
       "      <td>374.00</td>\n",
       "      <td>275.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/02/2022 4:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>430</td>\n",
       "      <td>1782.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>533.7</td>\n",
       "      <td>377.00</td>\n",
       "      <td>253.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19701</th>\n",
       "      <td>01/05/2024 19:00</td>\n",
       "      <td>24.4</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>89</td>\n",
       "      <td>161.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>102.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19702</th>\n",
       "      <td>01/05/2024 20:00</td>\n",
       "      <td>23.7</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>102</td>\n",
       "      <td>206.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19703</th>\n",
       "      <td>01/05/2024 21:00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>107</td>\n",
       "      <td>235.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>65.3</td>\n",
       "      <td>38.00</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19704</th>\n",
       "      <td>01/05/2024 22:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>112</td>\n",
       "      <td>264.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.3</td>\n",
       "      <td>67.7</td>\n",
       "      <td>40.00</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19705</th>\n",
       "      <td>01/05/2024 23:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>118</td>\n",
       "      <td>293.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19706 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp_local  temp city_name country_code  aqi      co   no2  \\\n",
       "0       01/02/2022 0:00  12.6    Gujrāt           PK  385  1339.8  76.0   \n",
       "1       01/02/2022 1:00  11.5    Gujrāt           PK  404  1437.6  76.0   \n",
       "2       01/02/2022 2:00  11.9    Gujrāt           PK  421  1535.5  76.0   \n",
       "3       01/02/2022 3:00  12.2    Gujrāt           PK  425  1659.0  68.3   \n",
       "4       01/02/2022 4:00  11.9    Gujrāt           PK  430  1782.5  60.7   \n",
       "...                 ...   ...       ...          ...  ...     ...   ...   \n",
       "19701  01/05/2024 19:00  24.4    Gujrāt           PK   89   161.5  22.3   \n",
       "19702  01/05/2024 20:00  23.7    Gujrāt           PK  102   206.6  31.0   \n",
       "19703  01/05/2024 21:00  23.0    Gujrāt           PK  107   235.4  34.0   \n",
       "19704  01/05/2024 22:00  21.1    Gujrāt           PK  112   264.2  37.0   \n",
       "19705  01/05/2024 23:00  21.1    Gujrāt           PK  118   293.0  40.0   \n",
       "\n",
       "          o3   pm10    pm25    so2  \n",
       "0       10.7  491.7  347.67  238.0  \n",
       "1        9.3  508.3  359.33  268.0  \n",
       "2        8.0  525.0  371.00  298.0  \n",
       "3        5.3  529.3  374.00  275.7  \n",
       "4        2.7  533.7  377.00  253.3  \n",
       "...      ...    ...     ...    ...  \n",
       "19701  102.3   55.0   30.00   21.0  \n",
       "19702   79.0   63.0   36.00   25.0  \n",
       "19703   65.7   65.3   38.00   26.0  \n",
       "19704   52.3   67.7   40.00   27.0  \n",
       "19705   39.0   70.0   42.00   28.0  \n",
       "\n",
       "[19706 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50e177f6-2dc9-4607-8c40-2a1863f2a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19706 entries, 0 to 19705\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   timestamp_local  19706 non-null  object \n",
      " 1   temp             19706 non-null  float64\n",
      " 2   city_name        19706 non-null  object \n",
      " 3   country_code     19706 non-null  object \n",
      " 4   aqi              19706 non-null  int64  \n",
      " 5   co               19706 non-null  float64\n",
      " 6   no2              19706 non-null  float64\n",
      " 7   o3               19706 non-null  float64\n",
      " 8   pm10             19706 non-null  float64\n",
      " 9   pm25             19706 non-null  float64\n",
      " 10  so2              19706 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1a975d2-6ba6-417e-b6f1-1433550a8e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 321ms/step - loss: 0.0875 - val_loss: 0.0699 - learning_rate: 1.0000e-06\n",
      "Epoch 2/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 318ms/step - loss: 0.0867 - val_loss: 0.0697 - learning_rate: 1.0000e-06\n",
      "Epoch 3/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 318ms/step - loss: 0.0866 - val_loss: 0.0695 - learning_rate: 1.0000e-06\n",
      "Epoch 4/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 320ms/step - loss: 0.0870 - val_loss: 0.0692 - learning_rate: 1.0000e-06\n",
      "Epoch 5/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 329ms/step - loss: 0.0858 - val_loss: 0.0688 - learning_rate: 1.0000e-06\n",
      "Epoch 6/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 330ms/step - loss: 0.0855 - val_loss: 0.0683 - learning_rate: 1.0000e-06\n",
      "Epoch 7/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 316ms/step - loss: 0.0849 - val_loss: 0.0677 - learning_rate: 1.0000e-06\n",
      "Epoch 8/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 319ms/step - loss: 0.0845 - val_loss: 0.0669 - learning_rate: 1.0000e-06\n",
      "Epoch 9/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0833 - val_loss: 0.0657 - learning_rate: 1.0000e-06\n",
      "Epoch 10/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0818 - val_loss: 0.0639 - learning_rate: 1.0000e-06\n",
      "Epoch 11/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0785 - val_loss: 0.0607 - learning_rate: 1.0000e-06\n",
      "Epoch 12/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 344ms/step - loss: 0.0735 - val_loss: 0.0585 - learning_rate: 1.0000e-06\n",
      "Epoch 13/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 347ms/step - loss: 0.0718 - val_loss: 0.0571 - learning_rate: 1.0000e-06\n",
      "Epoch 14/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 334ms/step - loss: 0.0702 - val_loss: 0.0557 - learning_rate: 1.0000e-06\n",
      "Epoch 15/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 333ms/step - loss: 0.0681 - val_loss: 0.0544 - learning_rate: 1.0000e-06\n",
      "Epoch 16/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0664 - val_loss: 0.0531 - learning_rate: 1.0000e-06\n",
      "Epoch 17/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 295ms/step - loss: 0.0647 - val_loss: 0.0518 - learning_rate: 1.0000e-06\n",
      "Epoch 18/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 293ms/step - loss: 0.0627 - val_loss: 0.0506 - learning_rate: 1.0000e-06\n",
      "Epoch 19/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 314ms/step - loss: 0.0608 - val_loss: 0.0493 - learning_rate: 1.0000e-06\n",
      "Epoch 20/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 299ms/step - loss: 0.0594 - val_loss: 0.0480 - learning_rate: 1.0000e-06\n",
      "Epoch 21/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 304ms/step - loss: 0.0580 - val_loss: 0.0469 - learning_rate: 1.0000e-06\n",
      "Epoch 22/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 332ms/step - loss: 0.0569 - val_loss: 0.0456 - learning_rate: 1.0000e-06\n",
      "Epoch 23/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 318ms/step - loss: 0.0550 - val_loss: 0.0444 - learning_rate: 1.0000e-06\n",
      "Epoch 24/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 314ms/step - loss: 0.0537 - val_loss: 0.0431 - learning_rate: 1.0000e-06\n",
      "Epoch 25/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 319ms/step - loss: 0.0517 - val_loss: 0.0419 - learning_rate: 1.0000e-06\n",
      "Epoch 26/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 303ms/step - loss: 0.0503 - val_loss: 0.0406 - learning_rate: 1.0000e-06\n",
      "Epoch 27/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 312ms/step - loss: 0.0488 - val_loss: 0.0394 - learning_rate: 1.0000e-06\n",
      "Epoch 28/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 304ms/step - loss: 0.0473 - val_loss: 0.0381 - learning_rate: 1.0000e-06\n",
      "Epoch 29/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0461 - val_loss: 0.0369 - learning_rate: 1.0000e-06\n",
      "Epoch 30/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 302ms/step - loss: 0.0444 - val_loss: 0.0356 - learning_rate: 1.0000e-06\n",
      "Epoch 31/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 296ms/step - loss: 0.0427 - val_loss: 0.0343 - learning_rate: 1.0000e-06\n",
      "Epoch 32/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 299ms/step - loss: 0.0416 - val_loss: 0.0330 - learning_rate: 1.0000e-06\n",
      "Epoch 33/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 298ms/step - loss: 0.0402 - val_loss: 0.0318 - learning_rate: 1.0000e-06\n",
      "Epoch 34/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 295ms/step - loss: 0.0392 - val_loss: 0.0308 - learning_rate: 1.0000e-06\n",
      "Epoch 35/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 296ms/step - loss: 0.0379 - val_loss: 0.0296 - learning_rate: 1.0000e-06\n",
      "Epoch 36/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 302ms/step - loss: 0.0369 - val_loss: 0.0286 - learning_rate: 1.0000e-06\n",
      "Epoch 37/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 301ms/step - loss: 0.0359 - val_loss: 0.0277 - learning_rate: 1.0000e-06\n",
      "Epoch 38/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0348 - val_loss: 0.0266 - learning_rate: 1.0000e-06\n",
      "Epoch 39/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0339 - val_loss: 0.0257 - learning_rate: 1.0000e-06\n",
      "Epoch 40/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0329 - val_loss: 0.0247 - learning_rate: 1.0000e-06\n",
      "Epoch 41/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 298ms/step - loss: 0.0320 - val_loss: 0.0237 - learning_rate: 1.0000e-06\n",
      "Epoch 42/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 291ms/step - loss: 0.0311 - val_loss: 0.0228 - learning_rate: 1.0000e-06\n",
      "Epoch 43/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 316ms/step - loss: 0.0302 - val_loss: 0.0220 - learning_rate: 1.0000e-06\n",
      "Epoch 44/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 295ms/step - loss: 0.0294 - val_loss: 0.0211 - learning_rate: 1.0000e-06\n",
      "Epoch 45/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 301ms/step - loss: 0.0285 - val_loss: 0.0203 - learning_rate: 1.0000e-06\n",
      "Epoch 46/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 296ms/step - loss: 0.0277 - val_loss: 0.0195 - learning_rate: 1.0000e-06\n",
      "Epoch 47/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 290ms/step - loss: 0.0272 - val_loss: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 48/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0266 - val_loss: 0.0181 - learning_rate: 1.0000e-06\n",
      "Epoch 49/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 306ms/step - loss: 0.0259 - val_loss: 0.0174 - learning_rate: 1.0000e-06\n",
      "Epoch 50/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 293ms/step - loss: 0.0254 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
      "Epoch 51/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 296ms/step - loss: 0.0248 - val_loss: 0.0162 - learning_rate: 1.0000e-06\n",
      "Epoch 52/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 300ms/step - loss: 0.0242 - val_loss: 0.0157 - learning_rate: 1.0000e-06\n",
      "Epoch 53/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 300ms/step - loss: 0.0238 - val_loss: 0.0152 - learning_rate: 1.0000e-06\n",
      "Epoch 54/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 298ms/step - loss: 0.0236 - val_loss: 0.0148 - learning_rate: 1.0000e-06\n",
      "Epoch 55/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 299ms/step - loss: 0.0232 - val_loss: 0.0144 - learning_rate: 1.0000e-06\n",
      "Epoch 56/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 293ms/step - loss: 0.0231 - val_loss: 0.0140 - learning_rate: 1.0000e-06\n",
      "Epoch 57/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 300ms/step - loss: 0.0227 - val_loss: 0.0137 - learning_rate: 1.0000e-06\n",
      "Epoch 58/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 306ms/step - loss: 0.0223 - val_loss: 0.0134 - learning_rate: 1.0000e-06\n",
      "Epoch 59/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 297ms/step - loss: 0.0219 - val_loss: 0.0131 - learning_rate: 1.0000e-06\n",
      "Epoch 60/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 299ms/step - loss: 0.0216 - val_loss: 0.0129 - learning_rate: 1.0000e-06\n",
      "Epoch 61/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 294ms/step - loss: 0.0218 - val_loss: 0.0126 - learning_rate: 1.0000e-06\n",
      "Epoch 62/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 292ms/step - loss: 0.0214 - val_loss: 0.0125 - learning_rate: 1.0000e-06\n",
      "Epoch 63/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 292ms/step - loss: 0.0214 - val_loss: 0.0123 - learning_rate: 1.0000e-06\n",
      "Epoch 64/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 292ms/step - loss: 0.0211 - val_loss: 0.0121 - learning_rate: 1.0000e-06\n",
      "Epoch 65/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 306ms/step - loss: 0.0209 - val_loss: 0.0120 - learning_rate: 1.0000e-06\n",
      "Epoch 66/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 309ms/step - loss: 0.0206 - val_loss: 0.0118 - learning_rate: 1.0000e-06\n",
      "Epoch 67/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 317ms/step - loss: 0.0209 - val_loss: 0.0117 - learning_rate: 1.0000e-06\n",
      "Epoch 68/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0204 - val_loss: 0.0116 - learning_rate: 1.0000e-06\n",
      "Epoch 69/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 339ms/step - loss: 0.0206 - val_loss: 0.0115 - learning_rate: 1.0000e-06\n",
      "Epoch 70/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 334ms/step - loss: 0.0203 - val_loss: 0.0114 - learning_rate: 1.0000e-06\n",
      "Epoch 71/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 313ms/step - loss: 0.0204 - val_loss: 0.0113 - learning_rate: 1.0000e-06\n",
      "Epoch 72/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 327ms/step - loss: 0.0201 - val_loss: 0.0113 - learning_rate: 1.0000e-06\n",
      "Epoch 73/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 353ms/step - loss: 0.0202 - val_loss: 0.0112 - learning_rate: 1.0000e-06\n",
      "Epoch 74/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 325ms/step - loss: 0.0200 - val_loss: 0.0112 - learning_rate: 1.0000e-06\n",
      "Epoch 75/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 310ms/step - loss: 0.0201 - val_loss: 0.0111 - learning_rate: 1.0000e-06\n",
      "Epoch 76/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 354ms/step - loss: 0.0201 - val_loss: 0.0110 - learning_rate: 1.0000e-06\n",
      "Epoch 77/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 347ms/step - loss: 0.0203 - val_loss: 0.0110 - learning_rate: 1.0000e-06\n",
      "Epoch 78/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 355ms/step - loss: 0.0201 - val_loss: 0.0109 - learning_rate: 1.0000e-06\n",
      "Epoch 79/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 332ms/step - loss: 0.0200 - val_loss: 0.0109 - learning_rate: 1.0000e-06\n",
      "Epoch 80/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 335ms/step - loss: 0.0202 - val_loss: 0.0109 - learning_rate: 1.0000e-06\n",
      "Epoch 81/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 351ms/step - loss: 0.0201 - val_loss: 0.0108 - learning_rate: 1.0000e-06\n",
      "Epoch 82/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 311ms/step - loss: 0.0201 - val_loss: 0.0108 - learning_rate: 1.0000e-06\n",
      "Epoch 83/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 300ms/step - loss: 0.0197 - val_loss: 0.0108 - learning_rate: 1.0000e-06\n",
      "Epoch 84/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 302ms/step - loss: 0.0198 - val_loss: 0.0107 - learning_rate: 1.0000e-06\n",
      "Epoch 85/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 318ms/step - loss: 0.0198 - val_loss: 0.0107 - learning_rate: 1.0000e-06\n",
      "Epoch 86/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 314ms/step - loss: 0.0201 - val_loss: 0.0107 - learning_rate: 1.0000e-06\n",
      "Epoch 87/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 310ms/step - loss: 0.0199 - val_loss: 0.0106 - learning_rate: 1.0000e-06\n",
      "Epoch 88/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 306ms/step - loss: 0.0200 - val_loss: 0.0106 - learning_rate: 1.0000e-06\n",
      "Epoch 89/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 300ms/step - loss: 0.0198 - val_loss: 0.0106 - learning_rate: 1.0000e-06\n",
      "Epoch 90/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 314ms/step - loss: 0.0197 - val_loss: 0.0105 - learning_rate: 1.0000e-06\n",
      "Epoch 91/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 351ms/step - loss: 0.0196 - val_loss: 0.0105 - learning_rate: 1.0000e-06\n",
      "Epoch 92/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 382ms/step - loss: 0.0194 - val_loss: 0.0105 - learning_rate: 1.0000e-06\n",
      "Epoch 93/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 472ms/step - loss: 0.0195 - val_loss: 0.0105 - learning_rate: 1.0000e-06\n",
      "Epoch 94/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 334ms/step - loss: 0.0196 - val_loss: 0.0104 - learning_rate: 1.0000e-06\n",
      "Epoch 95/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 397ms/step - loss: 0.0196 - val_loss: 0.0104 - learning_rate: 1.0000e-06\n",
      "Epoch 96/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 304ms/step - loss: 0.0197 - val_loss: 0.0104 - learning_rate: 1.0000e-06\n",
      "Epoch 97/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 306ms/step - loss: 0.0194 - val_loss: 0.0103 - learning_rate: 1.0000e-06\n",
      "Epoch 98/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 311ms/step - loss: 0.0195 - val_loss: 0.0103 - learning_rate: 1.0000e-06\n",
      "Epoch 99/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 313ms/step - loss: 0.0192 - val_loss: 0.0103 - learning_rate: 1.0000e-06\n",
      "Epoch 100/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 310ms/step - loss: 0.0193 - val_loss: 0.0103 - learning_rate: 1.0000e-06\n",
      "Epoch 101/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 305ms/step - loss: 0.0195 - val_loss: 0.0102 - learning_rate: 1.0000e-06\n",
      "Epoch 102/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 299ms/step - loss: 0.0193 - val_loss: 0.0102 - learning_rate: 1.0000e-06\n",
      "Epoch 103/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 309ms/step - loss: 0.0192 - val_loss: 0.0101 - learning_rate: 1.0000e-06\n",
      "Epoch 104/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 298ms/step - loss: 0.0191 - val_loss: 0.0101 - learning_rate: 1.0000e-06\n",
      "Epoch 105/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 310ms/step - loss: 0.0191 - val_loss: 0.0101 - learning_rate: 1.0000e-06\n",
      "Epoch 106/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 307ms/step - loss: 0.0190 - val_loss: 0.0100 - learning_rate: 1.0000e-06\n",
      "Epoch 107/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 310ms/step - loss: 0.0189 - val_loss: 0.0100 - learning_rate: 1.0000e-06\n",
      "Epoch 108/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 298ms/step - loss: 0.0189 - val_loss: 0.0099 - learning_rate: 1.0000e-06\n",
      "Epoch 109/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 317ms/step - loss: 0.0190 - val_loss: 0.0099 - learning_rate: 1.0000e-06\n",
      "Epoch 110/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 314ms/step - loss: 0.0189 - val_loss: 0.0099 - learning_rate: 1.0000e-06\n",
      "Epoch 111/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 304ms/step - loss: 0.0188 - val_loss: 0.0098 - learning_rate: 1.0000e-06\n",
      "Epoch 112/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 303ms/step - loss: 0.0189 - val_loss: 0.0098 - learning_rate: 1.0000e-06\n",
      "Epoch 113/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 302ms/step - loss: 0.0184 - val_loss: 0.0097 - learning_rate: 1.0000e-06\n",
      "Epoch 114/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 324ms/step - loss: 0.0185 - val_loss: 0.0097 - learning_rate: 1.0000e-06\n",
      "Epoch 115/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0187 - val_loss: 0.0096 - learning_rate: 1.0000e-06\n",
      "Epoch 116/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0185 - val_loss: 0.0096 - learning_rate: 1.0000e-06\n",
      "Epoch 117/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0184 - val_loss: 0.0095 - learning_rate: 1.0000e-06\n",
      "Epoch 118/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0183 - val_loss: 0.0095 - learning_rate: 1.0000e-06\n",
      "Epoch 119/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0182 - val_loss: 0.0094 - learning_rate: 1.0000e-06\n",
      "Epoch 120/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0182 - val_loss: 0.0094 - learning_rate: 1.0000e-06\n",
      "Epoch 121/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0185 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 122/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 323ms/step - loss: 0.0181 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 123/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 337ms/step - loss: 0.0181 - val_loss: 0.0093 - learning_rate: 1.0000e-06\n",
      "Epoch 124/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0180 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 125/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 348ms/step - loss: 0.0178 - val_loss: 0.0092 - learning_rate: 1.0000e-06\n",
      "Epoch 126/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0177 - val_loss: 0.0091 - learning_rate: 1.0000e-06\n",
      "Epoch 127/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0179 - val_loss: 0.0091 - learning_rate: 1.0000e-06\n",
      "Epoch 128/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0176 - val_loss: 0.0090 - learning_rate: 1.0000e-06\n",
      "Epoch 129/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0175 - val_loss: 0.0090 - learning_rate: 1.0000e-06\n",
      "Epoch 130/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0176 - val_loss: 0.0090 - learning_rate: 1.0000e-06\n",
      "Epoch 131/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 349ms/step - loss: 0.0175 - val_loss: 0.0089 - learning_rate: 1.0000e-06\n",
      "Epoch 132/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0174 - val_loss: 0.0089 - learning_rate: 1.0000e-06\n",
      "Epoch 133/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0172 - val_loss: 0.0088 - learning_rate: 1.0000e-06\n",
      "Epoch 134/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0173 - val_loss: 0.0088 - learning_rate: 1.0000e-06\n",
      "Epoch 135/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0172 - val_loss: 0.0087 - learning_rate: 1.0000e-06\n",
      "Epoch 136/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0171 - val_loss: 0.0087 - learning_rate: 1.0000e-06\n",
      "Epoch 137/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0173 - val_loss: 0.0086 - learning_rate: 1.0000e-06\n",
      "Epoch 138/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0170 - val_loss: 0.0086 - learning_rate: 1.0000e-06\n",
      "Epoch 139/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0169 - val_loss: 0.0086 - learning_rate: 1.0000e-06\n",
      "Epoch 140/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0168 - val_loss: 0.0085 - learning_rate: 1.0000e-06\n",
      "Epoch 141/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0169 - val_loss: 0.0085 - learning_rate: 1.0000e-06\n",
      "Epoch 142/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 337ms/step - loss: 0.0169 - val_loss: 0.0084 - learning_rate: 1.0000e-06\n",
      "Epoch 143/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0166 - val_loss: 0.0084 - learning_rate: 1.0000e-06\n",
      "Epoch 144/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0166 - val_loss: 0.0084 - learning_rate: 1.0000e-06\n",
      "Epoch 145/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0165 - val_loss: 0.0083 - learning_rate: 1.0000e-06\n",
      "Epoch 146/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0167 - val_loss: 0.0083 - learning_rate: 1.0000e-06\n",
      "Epoch 147/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0165 - val_loss: 0.0083 - learning_rate: 1.0000e-06\n",
      "Epoch 148/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 318ms/step - loss: 0.0165 - val_loss: 0.0082 - learning_rate: 1.0000e-06\n",
      "Epoch 149/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 322ms/step - loss: 0.0164 - val_loss: 0.0082 - learning_rate: 1.0000e-06\n",
      "Epoch 150/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0164 - val_loss: 0.0082 - learning_rate: 1.0000e-06\n",
      "Epoch 151/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0164 - val_loss: 0.0081 - learning_rate: 1.0000e-06\n",
      "Epoch 152/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0162 - val_loss: 0.0081 - learning_rate: 1.0000e-06\n",
      "Epoch 153/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0164 - val_loss: 0.0081 - learning_rate: 1.0000e-06\n",
      "Epoch 154/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0160 - val_loss: 0.0081 - learning_rate: 1.0000e-06\n",
      "Epoch 155/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 339ms/step - loss: 0.0161 - val_loss: 0.0080 - learning_rate: 1.0000e-06\n",
      "Epoch 156/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0161 - val_loss: 0.0080 - learning_rate: 1.0000e-06\n",
      "Epoch 157/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0158 - val_loss: 0.0080 - learning_rate: 1.0000e-06\n",
      "Epoch 158/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0161 - val_loss: 0.0080 - learning_rate: 1.0000e-06\n",
      "Epoch 159/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0159 - val_loss: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 160/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0160 - val_loss: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 161/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0159 - val_loss: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 162/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0159 - val_loss: 0.0079 - learning_rate: 1.0000e-06\n",
      "Epoch 163/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0156 - val_loss: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 164/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0157 - val_loss: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 165/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 338ms/step - loss: 0.0158 - val_loss: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 166/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0156 - val_loss: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 167/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0155 - val_loss: 0.0078 - learning_rate: 1.0000e-06\n",
      "Epoch 168/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0157 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 169/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0157 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 170/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 348ms/step - loss: 0.0156 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 171/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 348ms/step - loss: 0.0155 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 172/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0154 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 173/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 341ms/step - loss: 0.0157 - val_loss: 0.0077 - learning_rate: 1.0000e-06\n",
      "Epoch 174/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 344ms/step - loss: 0.0155 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 175/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 344ms/step - loss: 0.0155 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 176/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 344ms/step - loss: 0.0153 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 177/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0153 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 178/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0152 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 179/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 340ms/step - loss: 0.0154 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 180/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0154 - val_loss: 0.0076 - learning_rate: 1.0000e-06\n",
      "Epoch 181/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 344ms/step - loss: 0.0153 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 182/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0151 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 183/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0152 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 184/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 347ms/step - loss: 0.0153 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 185/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 347ms/step - loss: 0.0153 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 186/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 343ms/step - loss: 0.0152 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 187/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0151 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 188/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 350ms/step - loss: 0.0151 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 189/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0151 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 190/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 347ms/step - loss: 0.0151 - val_loss: 0.0075 - learning_rate: 1.0000e-06\n",
      "Epoch 191/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0150 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 192/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 346ms/step - loss: 0.0151 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 193/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 348ms/step - loss: 0.0150 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 194/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 349ms/step - loss: 0.0151 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 195/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0152 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 196/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 351ms/step - loss: 0.0150 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 197/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 351ms/step - loss: 0.0149 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 198/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 349ms/step - loss: 0.0149 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 199/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 347ms/step - loss: 0.0150 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 200/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 348ms/step - loss: 0.0150 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 201/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 353ms/step - loss: 0.0148 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 202/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0149 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 203/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 350ms/step - loss: 0.0148 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 204/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 345ms/step - loss: 0.0148 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 205/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 342ms/step - loss: 0.0149 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 206/500\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 482ms/step - loss: 0.0149 - val_loss: 0.0074 - learning_rate: 1.0000e-06\n",
      "Epoch 207/500\n",
      "\u001b[1m 34/388\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25\u001b[0m 749ms/step - loss: 0.0147"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# loss = model.evaluate(X_test, y_test, verbose=1)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# print(f'Test Loss: {loss}')\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     69\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Add time-based features\n",
    "# df['timestamp_local'] = pd.to_datetime(df['timestamp_local'], format=\"%d/%m/%Y %H:%M\")\n",
    "# df['hour'] = df['timestamp_local'].dt.hour\n",
    "# df['day_of_week'] = df['timestamp_local'].dt.dayofweek\n",
    "# df['month'] = df['timestamp_local'].dt.month\n",
    "\n",
    "# Drop non-numeric columns and set index\n",
    "# df = df.drop(columns=['hour', 'day_of_week', 'month'])\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(data, seq_length, n_steps_ahead):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length - n_steps_ahead + 1):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length:i+seq_length+n_steps_ahead]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "SEQ_LENGTH = 168\n",
    "N_STEPS_AHEAD = 168\n",
    "\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH, N_STEPS_AHEAD)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(SEQ_LENGTH, X.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64, activation='relu', return_sequences=True)))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(N_STEPS_AHEAD * X.shape[2]))  # Output layer to match the shape of the prediction\n",
    "model.add(tf.keras.layers.Reshape((N_STEPS_AHEAD, X.shape[2])))  # Reshape to match the expected output shape\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001), loss='mse')\n",
    "\n",
    "# Add early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2, verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "# loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "# print(f'Test Loss: {loss}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, X.shape[2]))\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, X.shape[2]))\n",
    "\n",
    "print(f'Predictions: {y_pred_inv}')\n",
    "print(f'Actual Values: {y_test_inv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "663d17b9-0a6a-4059-ab17-71500455a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62f518bd-fcd4-41b6-89fa-4822574650af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.8 , 184.  , 517.7 ,  63.3 ,  18.7 , 120.7 ,  81.33,  58.  ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_inv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3a7a2c0-16b1-43bb-8dd2-7c8b334472da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17b157b8-ce43-4627-8e1e-e3d234d53a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.7568938202174"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e668-11f7-4178-bd74-b335f243e08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cd034-f4df-43fe-b861-ae9d994006e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec25d75-b06d-4ff0-8323-9d2aa88f3234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee633f-4ca4-449e-b1ca-fd551fdfaee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798fd70-ae5b-4ce7-b16b-ef4de39c4f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e0cc9-e512-4f17-b621-fc96f9616df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf31517-8a08-40c9-b6dd-baa688048429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613156d-e244-4b86-8de9-f287f4b40477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd612f-167d-487f-9e47-708e2748d266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1d494-cf16-4a5a-988c-98cf0ef0d62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710d8ad-be67-44fa-ad05-216043bd5743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdec3d6-679a-4f34-95bd-2d34e269dd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a7ec8-cb54-418a-ac73-18c77036b403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18178b5e-ca6b-49bf-8a9e-7d890ff558bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the LSTM model\n",
    "def create_dataset(data, time_step=1, forecast_horizon=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - forecast_horizon):\n",
    "        X.append(data[i:(i + time_step)])\n",
    "        y.append(data[(i + time_step):(i + time_step + forecast_horizon)])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7453b9eb-a46e-4d47-92f3-63655fcd991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_local</th>\n",
       "      <th>temp</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>so2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/2022 0:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>385</td>\n",
       "      <td>1339.8</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>491.7</td>\n",
       "      <td>347.67</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2022 1:00</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>404</td>\n",
       "      <td>1437.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>508.3</td>\n",
       "      <td>359.33</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/02/2022 2:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>421</td>\n",
       "      <td>1535.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>371.00</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/02/2022 3:00</td>\n",
       "      <td>12.2</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>425</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>68.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>529.3</td>\n",
       "      <td>374.00</td>\n",
       "      <td>275.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/02/2022 4:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>Gujrāt</td>\n",
       "      <td>PK</td>\n",
       "      <td>430</td>\n",
       "      <td>1782.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>533.7</td>\n",
       "      <td>377.00</td>\n",
       "      <td>253.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp_local  temp city_name country_code  aqi      co   no2    o3  \\\n",
       "0  01/02/2022 0:00  12.6    Gujrāt           PK  385  1339.8  76.0  10.7   \n",
       "1  01/02/2022 1:00  11.5    Gujrāt           PK  404  1437.6  76.0   9.3   \n",
       "2  01/02/2022 2:00  11.9    Gujrāt           PK  421  1535.5  76.0   8.0   \n",
       "3  01/02/2022 3:00  12.2    Gujrāt           PK  425  1659.0  68.3   5.3   \n",
       "4  01/02/2022 4:00  11.9    Gujrāt           PK  430  1782.5  60.7   2.7   \n",
       "\n",
       "    pm10    pm25    so2  \n",
       "0  491.7  347.67  238.0  \n",
       "1  508.3  359.33  268.0  \n",
       "2  525.0  371.00  298.0  \n",
       "3  529.3  374.00  275.7  \n",
       "4  533.7  377.00  253.3  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed76cad7-0837-4c55-ad4b-4cae5b681c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[['temp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bd0627af-01f2-457b-b8ef-a82766457fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with a lookback of 24 hours and a forecast horizon of 12 hours\n",
    "time_step = 24\n",
    "forecast_horizon = 168\n",
    "X, y = create_dataset(scaled_data, time_step, forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "89dddfd4-c6c1-4b78-b8a4-5db8e5d7eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "52069b36-9c76-49b0-9f61-bf0d3b914909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data to be 3D [samples, time_steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "18ee7a8e-5e7b-4b0c-9345-b85965c80157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Build the LSTM model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "# model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(time_step, 1)))\n",
    "model.add(GRU(500))\n",
    "model.add(Dense(32*forecast_horizon))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(forecast_horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76ba45-a2f8-49b6-84d1-8bdfdab4537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">754,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,693,376</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,504</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">903,336</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m754,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5376\u001b[0m)                │       \u001b[38;5;34m2,693,376\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5376\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5376\u001b[0m)                │          \u001b[38;5;34m21,504\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)                 │         \u001b[38;5;34m903,336\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,372,716</span> (16.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,372,716\u001b[0m (16.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,361,964</span> (16.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,361,964\u001b[0m (16.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,752</span> (42.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,752\u001b[0m (42.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 392ms/step - loss: 0.1221 - val_loss: 0.0212\n",
      "Epoch 2/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 387ms/step - loss: 0.0085 - val_loss: 0.0170\n",
      "Epoch 3/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 381ms/step - loss: 0.0083 - val_loss: 0.0149\n",
      "Epoch 4/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 385ms/step - loss: 0.0083 - val_loss: 0.0118\n",
      "Epoch 5/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 377ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 6/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 379ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 7/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 390ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 8/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 393ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 9/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 379ms/step - loss: 0.0072 - val_loss: 0.0217\n",
      "Epoch 10/100\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 378ms/step - loss: 0.0077 - val_loss: 0.0089\n",
      "Epoch 11/100\n",
      "\u001b[1m113/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 350ms/step - loss: 0.0071"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4b95386-d09c-4a36-b858-c2e4c2a3f76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 369ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bd5cb62-62a0-4f27-9c5c-2d356216334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshaped = y_test.reshape((y_test.shape[0] * y_test.shape[1], 1))  # Reshape to 2D array\n",
    "y_test_inverse = scaler.inverse_transform(y_test_reshaped)\n",
    "y_test_inverse = y_test_inverse.reshape(y_test.shape)  # Reshape back to original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670c654c-f39c-4e46-8552-2a8cee82ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays for RMSE calculation\n",
    "y_test_flat = y_test_inverse.flatten()\n",
    "predicted_flat = predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44225445-818d-4184-bf01-543a436a949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test_flat, predicted_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "814e0051-47ec-4d0f-b2d7-c413a30dd391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.63367129638695"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae6cb0-1b32-499e-9833-113e0b322038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363551a5-b94a-49f4-94c1-32601d238071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
